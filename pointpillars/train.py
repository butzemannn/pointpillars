# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/10_train.ipynb (unless otherwise specified).

__all__ = ['ident_time', 'logger', 'log_format', 'log_formatter', 'log_handler', 'run_folder', 'writer', 'train',
           'validate']

# Cell
import logging
import torch
from torch.utils.tensorboard import SummaryWriter
import datetime
from torchviz import make_dot
from torch.profiler import profile, record_function, ProfilerActivity

from utils.io import read_config, save_network_checkpoint, save_network
from data.dataset import VelTrainDataset, collate_fn, OverfitSampler, collate_wrapper
from modules.pointpillars import PointPillars, init_weights
from modules.loss import PointPillarsLoss


#import os
#os.environ['PATH'] += os.pathsep + "/home/qhs67/anaconda3/envs/ba/lib/python3.8/site-packages/graphviz"


# Cell
# time to identify the run on folders and checkpoints etc
ident_time = datetime.datetime.now().strftime("%d-%m-%Y-%H-%M-%S")

# Cell
# logging
logger = logging.getLogger()
logger.setLevel(logging.WARNING)

log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
log_formatter = logging.Formatter(log_format)

log_handler = logging.FileHandler("/home/qhs67/git/bachelorthesis_sven_thaele/code/pointpillars.log", mode='w')
log_handler.setFormatter(log_formatter)
logger.addHandler(log_handler)

# Cell
# tensorboard writer
run_folder = "/home/qhs67/git/bachelorthesis_sven_thaele/code/runs/{}/".format(ident_time)

writer = SummaryWriter(run_folder)

# Cell
def _train_setup():
    """

    """
    batch_size = 3
    init_lr = 2 * 10**-4
    #init_lr = 1 * 10**-4

    logger.info("Start network training..")
    torch.cuda.empty_cache()
    #torch.backends.cudnn.benchmark = True
    torch.multiprocessing.set_start_method('spawn')
    # TODO: move to config file
    conf = read_config()
    vel_folder = "/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/velodyne/training"
    label_folder ="/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/label_2/training"
    ds_train = VelTrainDataset(vel_folder, label_folder)
    dl_train = torch.utils.data.DataLoader(ds_train,
                                           batch_size=batch_size,
                                           num_workers=1,
                                           collate_fn=collate_fn,
                                           pin_memory=False,
                                           shuffle=True)
    """sampler = OverfitSampler(ds_train, batch_size, nb_samples=20, shuffle=True)
    for i in sampler:
        print(i)
    dl_train = torch.utils.data.DataLoader(ds_train,
                                           batch_size=batch_size,
                                           sampler=sampler,
                                           num_workers=0,
                                           collate_fn=collate_fn)"""
    # modules
    pointpillars = PointPillars(conf)
    loss_func = PointPillarsLoss()
    pointpillars.train()
    loss_func.train()

    # TODO: also init bias?
    #pointpillars.apply(init_weights)
    # move to gpu
    pointpillars.cuda()
    loss_func.cuda()

    optimizer = torch.optim.Adam(pointpillars.parameters(), lr=init_lr)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30, gamma=0.8, last_epoch=-1)
    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2000, gamma=0.8, last_epoch=-1)

    return pointpillars, loss_func, optimizer, scheduler, dl_train

# Cell
def _train_step(batch: torch.Tensor,
               pointpillars: torch.nn.Module,
               loss_func: torch.nn.Module,
               optimizer: torch.optim.Adam,
               epoch: int,
               i: int) -> torch.nn.Module:
    """
    Performs a training step
    """
    pil_batch, ind_batch, label_batch, label_mask = batch

    # -> forward pass through network
    preds = pointpillars(pil_batch, ind_batch, label_batch, label_mask)
    loss = loss_func(preds=preds, writer=None, epoch=epoch, i=i)

    """dot = make_dot(loss, params=dict(pointpillars.named_parameters()), show_saved=True, show_attrs=True)
    dot.format = 'png'
    dot.render('torchviz-sample')"""
    loss.backward()
    optimizer.step()

    return loss

# Cell
def train(val: bool = False, save_nw: bool = False):
    """

    :param val: bool if validation should be used
    :param save_nw: bool if network state should be saved after training
    """
    n_epochs = 1

    pointpillars, loss_func, optimizer, scheduler, dl_train = _train_setup()


    try:
        for epoch in range(n_epochs):
            running_loss = 0
            for i, batch in enumerate(dl_train):
                if i >= 10:
                    break

                for param in pointpillars.parameters():
                    param.grad = None

                loss = _train_step(batch, pointpillars, loss_func, optimizer, epoch, i)
                #running_loss += loss.item()
                #print("Epoch: {}, Batch {} with Loss {} and running Loss {}.".format(epoch, i, loss.item(), running_loss/(i+1)))
                print("Epoch: {}, Batch {}.".format(epoch, i))
                #writer.add_scalar("Epoch {}/Running Loss".format(epoch), running_loss/(i+1), i)
                #writer.flush()
                #prof.step()

                # after epoch
                #scheduler.step()
                #writer.add_scalar("Epochs/Running Loss", running_loss/len(dl_train), epoch)
                #writer.add_scalar("Epochs/Learning Rate", scheduler.get_last_lr()[0], epoch)
                #writer.flush()
        #if val:
            #validate(pointpillars, loss_func, epoch, nbr_val_batches=100)
        # after training
        print('Finished Training')


    except Exception as e:
        print(e)
        logger.exception("An exception occured")
        save_network_checkpoint(pointpillars, optimizer, scheduler, loss, ident_time, epoch)
        exit()
    if save_nw:
        # save network to location from config
        save_network(pointpillars, ident_time, n_epochs)


    writer.close()

# Cell
def validate(network: torch.nn.Module, loss_func: torch.nn.Module, epoch, nbr_val_batches: int = 300):
    """
    Validates the network on the loss function on the validation dataset
    """
    batch_size = 3
    validation_folder = "/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/velodyne/validation"
    label_folder ="/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/label_2/validation"
    with torch.no_grad():
        ds_val = VelTrainDataset(validation_folder, label_folder)
        dl_val = torch.utils.data.DataLoader(ds_val,
                                           batch_size=batch_size,
                                           num_workers=4,
                                           collate_fn=collate_fn,
                                           pin_memory=True,
                                           shuffle=True)

        running_val_loss = 0
        for i, batch in enumerate(dl_val):
            # stop after given number of data
            if i >= nbr_val_batches:
                break
            pil_batch, ind_batch, label_batch, label_mask = batch
            preds = network(pil_batch, ind_batch, label_batch, label_mask)
            loss = loss_func(preds)
            running_val_loss += loss.item()

            print("Val Epoch: {}, Batch {} with Loss {} and running Loss {}.".format(epoch, i, loss.item(), running_val_loss/(i+1)))
            #writer.add_scalar("Epoch {}/Validation Loss".format(epoch), running_val_loss/(i+1), i)
            #writer.flush()

        writer.add_scalar("Epochs/Validation Loss", running_val_loss/nbr_val_batches, epoch)
        writer.flush()




# Cell
if __name__ == '__main__':
    train(save_nw=False)


