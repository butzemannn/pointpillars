{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils.math.box_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convert_boxes_to_2d_corners(boxes: torch.Tensor, batch_dim: bool = True) -> torch.Tensor:\n",
    "    \"\"\"Converts center representation to bounding corners\n",
    "    :param boxes: tensor(batch_size, nbr_boxes, nb_attributes)\n",
    "    :param batch_dim: Boolean if batch dim is used when converting\n",
    "\n",
    "    :returns: tensor(batch_size, max_nbr_pred_boxes, 4)\n",
    "                with last dimension being (x_min, y_min, x_max, y_max)\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_dim:\n",
    "        xy = boxes[:,:,:2]\n",
    "        lw = torch.stack((boxes[:,:,5], boxes[:,:,4]), dim=2)\n",
    "        dim = 2\n",
    "    else:\n",
    "        xy = boxes[:,:2]\n",
    "        lw = torch.stack((boxes[:,5], boxes[:,4]), dim=2)\n",
    "        dim = 1\n",
    "\n",
    "    xy_min = xy - 0.5 * lw\n",
    "    xy_max = xy + 0.5 * lw\n",
    "\n",
    "    return torch.cat([xy_min, xy_max], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convert_boxes_to_3d_corners(boxes: torch.Tensor, batch_dim: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts center representation to bounding corners. According to Kitti conventions, when calculating\n",
    "    z_min, 0 is subtracted and h is added to reach z_max.\n",
    "\n",
    "    :param boxes: Tensor(nbr_batches, nbr_boxes, 7) with latest dim being (x,y,z,h,w,l,theta)\n",
    "    :param batch_dim: Boolean if batch dimension is used when converting.\n",
    "\n",
    "    :returns: Tensor(nbr_batches, nbr_boxes, 6)\n",
    "                with latest dim being (x_min, y_min, z_min, x_max, y_max, z_max)\n",
    "    \"\"\"\n",
    "    if batch_dim:\n",
    "        xyz = boxes[:,:,:3]\n",
    "        lw = torch.stack((boxes[:,:,5], boxes[:,:,4]), dim=2)\n",
    "        h = boxes[:,:,3].unsqueeze(2)\n",
    "        dim = 2\n",
    "    else:\n",
    "        xyz = boxes[:,:3]\n",
    "        lw = torch.stack((boxes[:,5], boxes[:,4]), dim=1)\n",
    "        h = boxes[:,3].unsqueeze(1)\n",
    "        dim = 1\n",
    "\n",
    "    zeros = torch.zeros_like(h, device=\"cuda:0\")\n",
    "    xyz_min = xyz - torch.cat((0.5 * lw, zeros), dim=dim)\n",
    "    xyz_max = xyz + torch.cat((0.5 * lw, h), dim=dim)\n",
    "\n",
    "    return torch.cat([xyz_min, xyz_max], dim=dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5994, 0.6235, 0.1382, 0.5332, 0.2336, 0.5083, 0.0521],\n",
      "         [0.1153, 0.8175, 0.0230, 0.2062, 0.3402, 0.0817, 0.2251],\n",
      "         [0.6932, 0.0083, 0.5972, 0.8764, 0.0683, 0.0276, 0.4219],\n",
      "         [0.2351, 0.7263, 0.2560, 0.2200, 0.8178, 0.3944, 0.0321],\n",
      "         [0.7057, 0.3701, 0.5154, 0.4128, 0.9739, 0.2762, 0.1336]],\n",
      "\n",
      "        [[0.4584, 0.9925, 0.5483, 0.6735, 0.4109, 0.4803, 0.7455],\n",
      "         [0.4367, 0.1756, 0.1170, 0.3456, 0.4874, 0.9136, 0.9629],\n",
      "         [0.7565, 0.1352, 0.3870, 0.0571, 0.4442, 0.3100, 0.9955],\n",
      "         [0.1332, 0.5678, 0.9045, 0.5601, 0.2069, 0.5565, 0.4605],\n",
      "         [0.5226, 0.0381, 0.9285, 0.7056, 0.8407, 0.7728, 0.0536]]],\n",
      "       device='cuda:0') torch.Size([2, 5, 7])\n",
      "tensor([[[ 0.3452,  0.5067,  0.1382,  0.8535,  0.7403,  0.6714],\n",
      "         [ 0.0744,  0.6474,  0.0230,  0.1561,  0.9876,  0.2292],\n",
      "         [ 0.6794, -0.0259,  0.5972,  0.7070,  0.0425,  1.4736],\n",
      "         [ 0.0379,  0.3174,  0.2560,  0.4323,  1.1351,  0.4761],\n",
      "         [ 0.5676, -0.1169,  0.5154,  0.8438,  0.8570,  0.9282]],\n",
      "\n",
      "        [[ 0.2183,  0.7870,  0.5483,  0.6986,  1.1979,  1.2218],\n",
      "         [-0.0201, -0.0681,  0.1170,  0.8934,  0.4193,  0.4626],\n",
      "         [ 0.6015, -0.0869,  0.3870,  0.9115,  0.3573,  0.4440],\n",
      "         [-0.1450,  0.4644,  0.9045,  0.4115,  0.6713,  1.4646],\n",
      "         [ 0.1362, -0.3823,  0.9285,  0.9089,  0.4585,  1.6341]]],\n",
      "       device='cuda:0') torch.Size([2, 5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4858,  0.2053,  0.1950,  1.4665,  1.0767,  0.3175],\n",
       "         [ 0.9327,  0.7246,  0.9220,  1.0543,  1.0271,  1.4350],\n",
       "         [ 0.0180,  0.2924,  0.2576,  0.3644,  1.1814,  0.9629],\n",
       "         [ 0.2526, -0.4521,  0.2423,  0.3528,  0.5112,  0.7205],\n",
       "         [ 0.1033,  0.0934,  0.9031,  0.2518,  0.5868,  1.5131]],\n",
       "        device='cuda:0'),\n",
       " torch.Size([5, 6]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens1 = torch.rand((2, 5, 7), device=torch.device(\"cuda\"))\n",
    "tens2 = torch.rand((5, 7), device=torch.device(\"cuda\"))\n",
    "print(tens1, tens1.shape)\n",
    "out1 = convert_boxes_to_3d_corners(tens1, batch_dim=True)\n",
    "print(out1, out1.shape)\n",
    "out2 = convert_boxes_to_3d_corners(tens2, batch_dim=False)\n",
    "\n",
    "out2, out2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def bb_tensor_to_velodyne_coords(bb_cam: torch.Tensor):\n",
    "    xc, yc, zc, box_dims = bb_cam[:,0], bb_cam[:, 1], bb_cam[:, 2], bb_cam[:, 3:]\n",
    "\n",
    "    xv = zc\n",
    "    yv = -1 * xc\n",
    "    zv = -1 * yc\n",
    "\n",
    "    return torch.cat((xv.unsqueeze(1), yv.unsqueeze(1), zv.unsqueeze(1), box_dims), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def convert_vel_to_cam_coords(point: torch.Tensor, batch_dim: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts from velodyne coordinates to\n",
    "    \"\"\"\n",
    "    if batch_dim:\n",
    "        # TODO: implement batch_dim option\n",
    "        raise NotImplementedError(\"batch_dim option not yet implemented.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def vel_point_to_left_cam_point(y: torch.Tensor, calib_file: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "     Convert vel point to left color image:\n",
    "     x = P2 * R0_rect * Tr_velo_to_cam * y\n",
    "\n",
    "     :returns: Tensor(4) with x,y,z,1 in image coordinates and system\n",
    "    \"\"\"\n",
    "    # load transform data from calib folder\n",
    "\n",
    "\n",
    "    with open(calib_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        P2_l = [float(x) for x in lines[2].split(\" \")[1:]]\n",
    "        R0_l = [float(x) for x in lines[4].split(\" \")[1:]]\n",
    "        Tr_l = [float(x) for x in lines[5].split(\" \")[1:]]\n",
    "\n",
    "    P2 = torch.tensor([[P2_l[0], P2_l[1], P2_l[2], P2_l[3]],\n",
    "                       [P2_l[4], P2_l[5], P2_l[6], P2_l[7]],\n",
    "                       [P2_l[8], P2_l[9], P2_l[10], P2_l[11]]], device=torch.device(\"cuda\"))\n",
    "    R0 = torch.tensor([[R0_l[0], R0_l[1], R0_l[2], 0],\n",
    "                       [R0_l[3], R0_l[4], R0_l[5], 0],\n",
    "                       [R0_l[6], R0_l[7], R0_l[8], 0],\n",
    "                       [0,       0,       0,       1]], device=torch.device(\"cuda\"))\n",
    "    Tr = torch.tensor([[Tr_l[0], Tr_l[1], Tr_l[2],  Tr_l[3]],\n",
    "                       [Tr_l[4], Tr_l[5], Tr_l[6],  Tr_l[7]],\n",
    "                       [Tr_l[8], Tr_l[9], Tr_l[10], Tr_l[11]],\n",
    "                       [0,       0,       0,        1]], device=torch.device(\"cuda\"))\n",
    "\n",
    "    return P2 @ R0 @ Tr @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 102.5686,    0.3276, -170.9427])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calib_loc = \"/home/qhs67/git/bachelorthesis_sven_thaele/code/data/kitti/training/calib/000000.txt\"\n",
    "y = torch.FloatTensor([0, 0, 0, 1])\n",
    "\n",
    "vel_point_to_left_cam_point(y, calib_loc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba",
   "language": "python",
   "name": "ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}